{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent \n",
    "agents refer to systems or components that can autonomously decide what actions to take in a given environment. Agents typically use tools, such as APIs, databases, or retrieval mechanisms, to perform tasks in response to user queries or actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build an Agent with AgentExecutor (Legacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An agent in LangChain refers to a system that leverages a language model (LLM) to decide what actions to take based on input and available tools. Agents are built to perform a sequence of steps in response to user queries, interacting with external resources or tools, and utilizing the LLM to determine which tools to invoke and how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Concepts of LangChain Agents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM as Reasoning Engine: The language model is used to decide what actions need to be taken based on the input provided. The LLM doesn't perform actions directly; it suggests actions and determines inputs for those actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools: These are external functions, APIs, or resources that the agent can use. For example, tools can include search engines, databases, or custom functions that the agent can call to gather information or perform tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ction Execution: While the LLM decides on which actions to take, the actions themselves (like calling an API or retrieving data from a local database) are executed by the agent executor, not the LLM itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool Calls: Tools can be invoked by the agent based on the LLM's reasoning. The agent will pass arguments to the tools based on the query and the context it has, enabling dynamic responses and actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Agent with LangChain\n",
    "To build an agent in LangChain, you typically:\n",
    "\n",
    "Define tools (such as a search engine or a custom retriever over a dataset).\n",
    "\n",
    "Create a language model that can invoke these tools.\n",
    "\n",
    "Create the agent, which uses the LLM to decide which tools to call.\n",
    "\n",
    "Use the AgentExecutor to handle the execution of tools based on the agent's decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Walkthrough:\n",
    "\n",
    "* Define Tools:\n",
    "\n",
    "Tools could include a search tool like Tavily (for searching the web) or a retriever (for fetching data from a local index).\n",
    "\n",
    "* Set Up a Language Model:\n",
    "\n",
    "You can use various LLMs like OpenAI's GPT models or others to guide the agent's reasoning.\n",
    "\n",
    "* Create the Agent:\n",
    "\n",
    "The agent is responsible for determining which tool to call based on the user's input.\n",
    "\n",
    "* Use AgentExecutor:\n",
    "\n",
    "The AgentExecutor runs the agent, executes the actions, and returns the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.tools import TavilySearchAPIWrapper\n",
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "\n",
    "\n",
    "search = TavilySearchAPIWrapper(tavily_api_key=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "\n",
    "def create_retriever_tool(retriever, tool_name, tool_description):\n",
    "    # Wrapper function that calls the retriever\n",
    "    def retriever_function(query: str):\n",
    "        return retriever.get_relevant_documents(query)\n",
    "\n",
    "    # Create the tool using the wrapper function\n",
    "    return Tool(\n",
    "        name=tool_name,\n",
    "        func=retriever_function,  # Pass the callable function\n",
    "        description=tool_description\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': \"What's the weather in SF?\", 'output': 'The current weather in San Francisco, California is partly cloudy with a temperature of 7.8°C (46.0°F). The wind is coming from NE at a speed of 14.0 kph (8.7 mph). The humidity level is at 63%.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Define tools\n",
    "search = TavilySearchResults(max_results=2)\n",
    "loader = WebBaseLoader(\"https://www.accuweather.com/en/in/noida/3146227/daily-weather-forecast/3146227\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever_tool = create_retriever_tool(vector.as_retriever(), \"search_tool\", \"Search for relevant documents.\")\n",
    "\n",
    "tools = [search, retriever_tool]\n",
    "\n",
    "# Define the language model\n",
    "model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Create the agent\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "\n",
    "# Run the agent\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "response = agent_executor.invoke({\"input\": \"What's the weather in SF?\"})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How It Works:\n",
    "* Tools: The tools (like TavilySearchResults for web searches and a retriever_tool for fetching local data) are defined.\n",
    "* Agent: The agent decides which tools to invoke based on the user query.\n",
    "* Executor: The AgentExecutor actually runs the agent and invokes the tools to fetch data, returning the result to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain's agents are useful for building intelligent systems that can perform complex tasks like browsing the web, interacting with databases, and even remembering past interactions (if configured with chat history). They are designed to provide flexibility, enabling agents to dynamically adjust based on the inputs they receive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. How to migrate from legacy LangChain agents to LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To migrate from legacy LangChain agents to LangGraph agents, you need to make some adjustments in how you set up and invoke your agent logic. LangGraph's system is more flexible and streamlined compared to LangChain, especially when it comes to agent configuration, memory management, and iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic Setup\n",
    "In LangChain, agents like AgentExecutor are set up by defining a model, tools, and a prompt template. The AgentExecutor runs the agent with the configured tools and prompt. In LangGraph, this process is simplified, and you use the create_react_agent helper method to set up the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legacy LangChain AgentExecutor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'what is the value of magic_function(3)?', 'output': 'The value of magic_function(3) is 5.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Define the tool function with a docstring\n",
    "@tool\n",
    "def magic_function(input: int) -> int:\n",
    "    \"\"\"Adds 2 to the input value.\"\"\"\n",
    "    return input + 2\n",
    "\n",
    "# List of tools\n",
    "tools = [magic_function]\n",
    "\n",
    "# Define the prompt template (using valid message types)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You are a helpful assistant\"),\n",
    "     (\"human\", \"{input}\"),\n",
    "     (\"assistant\", \"{agent_scratchpad}\")  # Using \"assistant\" instead of \"agent\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the agent that will use the tool\n",
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "\n",
    "# Execute the agent\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "response = agent_executor.invoke({\"input\": \"what is the value of magic_function(3)?\"})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph Agent Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you?\n",
      "\n",
      "I'm a little bit of a nerd. I'm a big nerd. I'm a big nerd. I'm a big nerd. I'm a big nerd. I'm a big nerd. I'm a\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"  # Replace with the model name you prefer\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize input\n",
    "input_text = \"Hello, how are you?\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate a response\n",
    "outputs = model.generate(inputs['input_ids'], max_length=50)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Handling System Messages\n",
    "LangChain uses prompt templates with placeholders for the agent's scratchpad. In LangGraph, you can control agent behavior with a state_modifier, which allows you to modify the agent's state before the model is invoked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legacy LangChain with Prompt Template:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You are a helpful assistant. Respond only in Spanish.\"), (\"human\", \"{input}\")]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph with System Message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10856\\2390018418.py:5: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  model = OpenAI(model=\"gpt-3.5-turbo\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_react_agent() got an unexpected keyword argument 'state_modifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m system_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant. Respond only in Spanish.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Create the agent\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m langgraph_agent_executor \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_modifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_message\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Execute the agent with a query\u001b[39;00m\n\u001b[0;32m     19\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m¿Cómo estás?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: create_react_agent() got an unexpected keyword argument 'state_modifier'"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import create_react_agent\n",
    "\n",
    "# Initialize OpenAI model (make sure you have access to the API key)\n",
    "model = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define your tools (example)\n",
    "tools = []\n",
    "\n",
    "# Define system message for the assistant\n",
    "system_message = \"You are a helpful assistant. Respond only in Spanish.\"\n",
    "\n",
    "# Create the agent\n",
    "langgraph_agent_executor = create_react_agent(\n",
    "    model, tools, state_modifier=system_message\n",
    ")\n",
    "\n",
    "# Execute the agent with a query\n",
    "query = \"¿Cómo estás?\"\n",
    "messages = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "# Output the response\n",
    "print(messages[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
