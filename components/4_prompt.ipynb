{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. BasePromptTemplate\n",
    "This is the base class from which all prompt templates inherit. It provides common methods for handling prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the following text: The quick brown fox jumps over the lazy dog.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import BasePromptTemplate\n",
    "from pydantic import Field\n",
    "\n",
    "class MyPromptTemplate(BasePromptTemplate):\n",
    "    template: str = Field(...)\n",
    "    input_variables: list = Field(...)\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "    def format_prompt(self, **kwargs) -> str:\n",
    "        return self.format(**kwargs)\n",
    "\n",
    "template = \"Summarize the following text: {text}\"\n",
    "\n",
    "# Create an instance of MyPromptTemplate with the template and input variables\n",
    "prompt = MyPromptTemplate(template=template, input_variables=[\"text\"])\n",
    "\n",
    "# Now you can use the format method without any issues\n",
    "formatted_prompt = prompt.format(text=\"The quick brown fox jumps over the lazy dog.\")\n",
    "print(formatted_prompt)  # Output: Summarize the following text: The quick brown fox jumps over the lazy dog.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. AIMessagePromptTemplate\n",
    "This is specifically for AI-generated messages in chat-based applications. It's useful when interacting with AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Here is your answer.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import AIMessagePromptTemplate\n",
    "\n",
    "ai_template = AIMessagePromptTemplate.from_template(\"AI: {response}\")\n",
    "ai_message = ai_template.format(response=\"Here is your answer.\")\n",
    "print(ai_message.content)  # Output: AI: Here is your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. BaseChatPromptTemplate\n",
    "This is a base class for chat-based prompt templates. It's an abstract class that defines the structure for chat prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chatbot says: Hello']\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import BaseChatPromptTemplate\n",
    "from pydantic import Field\n",
    "\n",
    "class MyChatPromptTemplate(BaseChatPromptTemplate):\n",
    "    input_variables: list = Field(default_factory=list)\n",
    "\n",
    "    def format_messages(self, **kwargs):\n",
    "        return [f\"Chatbot says: {kwargs['user_message']}\"]\n",
    "\n",
    "# Create an instance of MyChatPromptTemplate\n",
    "template = MyChatPromptTemplate(input_variables=[\"user_message\"])\n",
    "\n",
    "# Test the format_messages method\n",
    "print(template.format_messages(user_message=\"Hello\"))  # Output: ['Chatbot says: Hello']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. BaseMessagePromptTemplate\n",
    "This class handles the structure of individual message prompts and is a base class for specific message templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: Welcome!\n",
      "['Message: Welcome!']\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import BaseMessagePromptTemplate\n",
    "from pydantic import Field\n",
    "\n",
    "class CustomMessagePromptTemplate(BaseMessagePromptTemplate):\n",
    "    input_variables: list = Field(default_factory=list)\n",
    "\n",
    "    def format(self, **kwargs):\n",
    "        return f\"Message: {kwargs['text']}\"\n",
    "\n",
    "    def format_messages(self, **kwargs):\n",
    "        return [self.format(**kwargs)]\n",
    "\n",
    "\n",
    "# Create an instance of CustomMessagePromptTemplate\n",
    "template = CustomMessagePromptTemplate(input_variables=[\"text\"])\n",
    "\n",
    "# Test the format method\n",
    "print(template.format(text=\"Welcome!\"))  # Output: Message: Welcome!\n",
    "\n",
    "# Test the format_messages method\n",
    "print(template.format_messages(text=\"Welcome!\"))  # Output: ['Message: Welcome!']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. BaseStringMessagePromptTemplate\n",
    "This is a more specific class dealing with string-based message prompts. It is typically inherited when handling string messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the weather today?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatMessagePromptTemplate\n",
    "\n",
    "# Specify the required role (e.g., \"user\")\n",
    "user_template = ChatMessagePromptTemplate.from_template(\n",
    "    template=\"User: {message}\",\n",
    "    role=\"user\"  # Define the role here\n",
    ")\n",
    "\n",
    "# Format the message with the given input\n",
    "formatted_message = user_template.format(message=\"What is the weather today?\")\n",
    "\n",
    "# Print the content of the formatted message\n",
    "print(formatted_message.content)  # Expected Output: User: What is the weather today?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. ChatMessagePromptTemplate\n",
    "This template is for a single chat message prompt, useful when working with multi-turn conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the weather today?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatMessagePromptTemplate\n",
    "\n",
    "# Define a role, in this case, \"user\"\n",
    "user_template = ChatMessagePromptTemplate.from_template(\"User: {message}\", role=\"user\")\n",
    "\n",
    "# Format the message\n",
    "formatted_message = user_template.format(message=\"What is the weather today?\")\n",
    "\n",
    "# Output the formatted message content\n",
    "print(formatted_message.content)  # Output: User: What is the weather today?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. ChatPromptTemplate\n",
    "This is used to create a conversation-style prompt with multiple messages from different speakers (e.g., human, AI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User: How are you?', \"AI: I'm good, thanks!\"]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [HumanMessagePromptTemplate.from_template(\"User: {user_message}\"),\n",
    "     AIMessagePromptTemplate.from_template(\"AI: {ai_response}\")]\n",
    ")\n",
    "\n",
    "prompt = chat_prompt.format_messages(user_message=\"How are you?\", ai_response=\"I'm good, thanks!\")\n",
    "print([msg.content for msg in prompt])  \n",
    "# Output: ['User: How are you?', \"AI: I'm good, thanks!\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. HumanMessagePromptTemplate\n",
    "This template formats messages from the human user. It is used in chat-based prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
    "\n",
    "user_template = HumanMessagePromptTemplate.from_template(\"Human: {text}\")\n",
    "print(user_template.format(text=\"Hello!\").content)  # Output: Human: Hello!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. MessagesPlaceholder\n",
    "This placeholder allows you to insert dynamic content into a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello\n",
      "AI: How can I help you?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Define a placeholder for previous messages\n",
    "placeholder = MessagesPlaceholder(variable_name=\"previous_messages\")\n",
    "\n",
    "# Create a prompt template that includes the placeholder\n",
    "prompt = ChatPromptTemplate.from_messages([placeholder])\n",
    "\n",
    "# Format the template by passing previous messages as a variable\n",
    "formatted_prompt = prompt.format(previous_messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"How can I help you?\"}\n",
    "])\n",
    "\n",
    "# Since formatted_prompt may be a string, simply print it directly.\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. SystemMessagePromptTemplate\n",
    "This template defines system messages, which set instructions or context for the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import SystemMessagePromptTemplate\n",
    "\n",
    "system_template = SystemMessagePromptTemplate.from_template(\"System: You are a helpful assistant.\")\n",
    "print(system_template.format().content)  # Output: System: You are a helpful assistant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. FewShotChatMessagePromptTemplate\n",
    "This is a specialized prompt template for few-shot learning, where a model is provided with a few examples to understand a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How are you?\n",
      "AI: I'm fine, thanks!\n",
      "User: What is your name?\n",
      "AI: I am a chatbot.\n",
      "User: What's your name?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create a few-shot prompt manually\n",
    "examples = [\n",
    "    {\"input\": \"How are you?\", \"output\": \"I'm fine, thanks!\"},\n",
    "    {\"input\": \"What is your name?\", \"output\": \"I am a chatbot.\"}\n",
    "]\n",
    "\n",
    "input_template = \"User: {input}\\n\"\n",
    "output_template = \"AI: {output}\\n\"\n",
    "\n",
    "# Combine examples into a single prompt\n",
    "few_shot_prompt = \"\".join(\n",
    "    input_template.format(input=example[\"input\"]) + output_template.format(output=example[\"output\"])\n",
    "    for example in examples\n",
    ")\n",
    "\n",
    "# Add the new input to the prompt\n",
    "new_input = \"What's your name?\"\n",
    "formatted_prompt = few_shot_prompt + input_template.format(input=new_input)\n",
    "\n",
    "# Output the formatted prompt\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. FewShotPromptTemplate\n",
    "Similar to the few-shot chat version, but designed for general non-chat applications where you give examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a language translator.\n",
      "\n",
      "Example: translate for 'Hello, how are you?' is 'Hola, ¿cómo estás?'.\n",
      "\n",
      "Example: translate for 'Thank you very much!' is '¡Muchas gracias!'.\n",
      "\n",
      "Complete the task: translate for 'What is your name?'.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "# Define the example prompt template for translation\n",
    "example_prompt_template = PromptTemplate(\n",
    "    template=\"Example: {task} for '{data}' is '{output}'.\",\n",
    "    input_variables=[\"task\", \"data\", \"output\"]\n",
    ")\n",
    "\n",
    "# Create a FewShotPromptTemplate for language translation\n",
    "few_shot_template = FewShotPromptTemplate(\n",
    "    examples=[\n",
    "        {\"task\": \"translate\", \"data\": \"Hello, how are you?\", \"output\": \"Hola, ¿cómo estás?\"},\n",
    "        {\"task\": \"translate\", \"data\": \"Thank you very much!\", \"output\": \"¡Muchas gracias!\"},\n",
    "    ],\n",
    "    example_prompt=example_prompt_template,  # Use example_prompt instead of example_prompt_template\n",
    "    input_variables=[\"task\", \"data\"],\n",
    "    prefix=\"You are a language translator.\",\n",
    "    suffix=\"Complete the task: {task} for '{data}'.\"\n",
    ")\n",
    "\n",
    "# Format the prompt with new input data\n",
    "prompt = few_shot_template.format(task=\"translate\", data=\"What is your name?\")\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. PipelinePromptTemplate\n",
    "This template allows combining multiple prompts into a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Example 1: Greeting, Product Information, and Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning How can I assist you today?\n",
      "\n",
      "You're interested in learning more about our products. Here are the details about our latest product Educative Bot.\n",
      "\n",
      "If you have any other questions, feel free to ask. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, PipelinePromptTemplate\n",
    "\n",
    "# Define the component prompt templates\n",
    "greeting_prompt = PromptTemplate.from_template(\"Good morning How can I assist you today?\")\n",
    "product_info_prompt = PromptTemplate.from_template(\"You're interested in learning more about our products. Here are the details about our latest product {product}.\")\n",
    "closing_prompt = PromptTemplate.from_template(\"If you have any other questions, feel free to ask. Have a great day!\")\n",
    "\n",
    "# Define the final prompt template that combines all parts\n",
    "full_template = \"\"\"{greeting}\n",
    "\n",
    "{content}\n",
    "\n",
    "{closing}\"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)\n",
    "\n",
    "# Assemble the pipeline prompts\n",
    "pipeline_prompts = [\n",
    "    (\"greeting\", greeting_prompt),\n",
    "    (\"content\", product_info_prompt),\n",
    "    (\"closing\", closing_prompt)\n",
    "]\n",
    "\n",
    "# Create the PipelinePromptTemplate\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=pipeline_prompts)\n",
    "\n",
    "# Example usage for product information\n",
    "formatted_prompt = pipeline_prompt.format(product=\"Educative Bot\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Example 2: Troubleshooting Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning How can I assist you today?\n",
      "\n",
      "It seems you're having trouble with Educative Bot. Let me guide you through some steps to resolve this.\n",
      "\n",
      "If you have any other questions, feel free to ask. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, PipelinePromptTemplate\n",
    "\n",
    "# Define the component prompt templates\n",
    "greeting_prompt = PromptTemplate.from_template(\"Good morning How can I assist you today?\")\n",
    "troubleshooting_prompt = PromptTemplate.from_template(\"It seems you're having trouble with {product}. Let me guide you through some steps to resolve this.\")\n",
    "closing_prompt = PromptTemplate.from_template(\"If you have any other questions, feel free to ask. Have a great day!\")\n",
    "\n",
    "# Define the final prompt template that combines all parts\n",
    "troubleshoot_template = \"\"\"{greeting}\n",
    "\n",
    "{trouble}\n",
    "\n",
    "{closing}\"\"\"\n",
    "full_prompt = PromptTemplate.from_template(troubleshoot_template)\n",
    "\n",
    "# Assemble the pipeline prompts\n",
    "pipeline_prompts = [\n",
    "    (\"greeting\", greeting_prompt),\n",
    "    (\"trouble\", troubleshooting_prompt),\n",
    "    (\"closing\", closing_prompt)\n",
    "]\n",
    "\n",
    "# Create the PipelinePromptTemplate\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=pipeline_prompts)\n",
    "\n",
    "# Example usage for troubleshooting\n",
    "formatted_prompt = pipeline_prompt.format(product=\"Educative Bot\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Example 3: Impersonation and Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are impersonating Elon Musk.\n",
      "\n",
      "Here's an example of an interaction:\n",
      "\n",
      "Q: What's your favorite car?\n",
      "A: Tesla\n",
      "\n",
      "Now, do this for real!\n",
      "\n",
      "Q: What's your favorite social media site?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, PipelinePromptTemplate\n",
    "\n",
    "# Define the component prompt templates\n",
    "introduction_template = \"\"\"You are impersonating {person}.\"\"\"\n",
    "introduction_prompt = PromptTemplate.from_template(introduction_template)\n",
    "\n",
    "example_template = \"\"\"Here's an example of an interaction:\n",
    "\n",
    "Q: {example_q}\n",
    "A: {example_a}\"\"\"\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "start_template = \"\"\"Now, do this for real!\n",
    "\n",
    "Q: {input}\n",
    "A:\"\"\"\n",
    "start_prompt = PromptTemplate.from_template(start_template)\n",
    "\n",
    "# Define the final prompt template that combines all parts\n",
    "full_template = \"\"\"{introduction}\n",
    "\n",
    "{example}\n",
    "\n",
    "{start}\"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)\n",
    "\n",
    "# Assemble the pipeline prompts\n",
    "pipeline_prompts = [\n",
    "    (\"introduction\", introduction_prompt),\n",
    "    (\"example\", example_prompt),\n",
    "    (\"start\", start_prompt)\n",
    "]\n",
    "\n",
    "# Create the PipelinePromptTemplate\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=pipeline_prompts)\n",
    "\n",
    "# Example usage\n",
    "formatted_prompt = pipeline_prompt.format(\n",
    "    person=\"Elon Musk\",\n",
    "    example_q=\"What's your favorite car?\",\n",
    "    example_a=\"Tesla\",\n",
    "    input=\"What's your favorite social media site?\"\n",
    ")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. PromptTemplate\n",
    "The core template for non-chat-based prompting. It handles dynamic string generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the following text: apple\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"Classify the following text: {text}\")\n",
    "prompt = template.format(text=\"apple\")\n",
    "print(prompt)  # Output: Classify the following text: apple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question-Answer Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instruction: Answer the question based on the context below. If you cannot answer the question with the given context, answer with \"I don't know.\"\n",
      "\n",
      "Context: Codecademy is an interactive online learning platform offering courses in various programming languages and tech skills.\n",
      "\n",
      "Query: What types of courses does Codecademy offer?\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "Instruction: Answer the question based on the context below. If you cannot answer the question with the given context, answer with \"I don't know.\"\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Example usage\n",
    "context = \"Codecademy is an interactive online learning platform offering courses in various programming languages and tech skills.\"\n",
    "query = \"What types of courses does Codecademy offer?\"\n",
    "prompt = prompt_template.format(context=context, query=query)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Text Summarization Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The sentence describes a quick brown fox jumping over a lazy dog. It is often used as an example in typing and typing games due to its use of all the alphabet letters.\n",
      "Task: classify, Data: apple, Output: fruit\n",
      "Classification result for 'apple': fruit\n",
      "We would love to hear your thoughts on our new mobile app. Please provide your feedback:\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Summarize the text\n",
    "text_to_summarize = \"The quick brown fox jumps over the lazy dog.\"\n",
    "summary = \"The sentence describes a quick brown fox jumping over a lazy dog. It is often used as an example in typing and typing games due to its use of all the alphabet letters.\"\n",
    "print(\"Summary:\", summary)\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate.from_template(\"Task: {task}, Data: {data}, Output: {output}\")\n",
    "\n",
    "# Format the prompt\n",
    "prompt = prompt_template.format(task=\"classify\", data=\"apple\", output=\"fruit\")\n",
    "print(prompt)  # Output: Task: classify, Data: apple, Output: fruit\n",
    "\n",
    "# Example classification function\n",
    "def classify_text(text):\n",
    "    return \"fruit\" if text.lower() == \"apple\" else \"unknown\"\n",
    "\n",
    "# Classifying the text\n",
    "classification_text = \"apple\"\n",
    "classification_result = classify_text(classification_text)\n",
    "print(f\"Classification result for '{classification_text}': {classification_result}\")\n",
    "\n",
    "# Define the feedback request template correctly\n",
    "feedback_template = PromptTemplate.from_template(\"We would love to hear your thoughts on {service}. Please provide your feedback:\")\n",
    "formatted_feedback_request = feedback_template.format(service=\"our new mobile app\")\n",
    "print(formatted_feedback_request)  # Output: \"We would love to hear your thoughts on our new mobile app. Please provide your feedback:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. StringPromptTemplate\n",
    "This is a string-based version of prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice'}, welcome!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts.string import StringPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Define a simple prompt template\n",
    "class CustomStringPromptTemplate(StringPromptTemplate):\n",
    "    def format(self, **kwargs) -> str:\n",
    "        return f\"{kwargs['name']}, welcome!\"  # Custom formatting logic\n",
    "\n",
    "# Create an instance of the custom template\n",
    "template = CustomStringPromptTemplate(\n",
    "    input_variables=[\"name\"],\n",
    "    input_types={\"name\": str},\n",
    ")\n",
    "\n",
    "# Create a function to use with the template\n",
    "async def generate_greeting(name: str) -> str:\n",
    "    formatted_prompt = template.format(name=name)\n",
    "    return formatted_prompt\n",
    "\n",
    "# Create a runnable from the function\n",
    "greeting_runnable = RunnableLambda(generate_greeting)\n",
    "\n",
    "# Example invocation using `ainvoke` for asynchronous execution\n",
    "output = await greeting_runnable.ainvoke({\"name\": \"Alice\"})  # Use ainvoke here\n",
    "print(output)  # Outputs: \"Alice, welcome!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
