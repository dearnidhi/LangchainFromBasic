{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to add ad-hoc tool calling capability to LLMs and Chat Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add ad-hoc tool calling capability to LLMs and chat models, we can use LangChain's tool system and create a prompt that instructs the model to invoke the right tool based on the user's input. Here's a step-by-step breakdown of the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8524\\2418719106.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  model = Ollama(model=\"phi3\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "model = Ollama(model=\"phi3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Tool\n",
    "You can define custom tools using the @tool decorator. Here's an example of two simple tools: multiply and add:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply two numbers together.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "@tool\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Add two numbers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "tools = [multiply, add]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Prompt\n",
    "We need a prompt that specifies the tools available, their descriptions, and the output format (JSON):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import render_text_description\n",
    "\n",
    "# Render tool descriptions\n",
    "rendered_tools = render_text_description(tools)\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are an assistant that has access to the following set of tools.\n",
    "Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "\n",
    "Given the user input, return the name and input of the tool to use.\n",
    "Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
    "\n",
    "The `arguments` should be a dictionary, with keys corresponding \n",
    "to the argument names and the values corresponding to the requested values.\n",
    "\"\"\"\n",
    "\n",
    "# Create prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt), (\"user\", \"{input}\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain Setup\n",
    "Next, create a chain that invokes the model and parses the output as JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | JsonOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke the Tool\n",
    "Now, the model will output which tool to use, along with the required arguments. We'll implement the logic to actually invoke the selected tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, Optional, TypedDict\n",
    "\n",
    "class ToolCallRequest(TypedDict):\n",
    "    \"\"\"A typed dict for tool invocation inputs.\"\"\"\n",
    "    name: str\n",
    "    arguments: Dict[str, Any]\n",
    "\n",
    "def invoke_tool(tool_call_request: ToolCallRequest):\n",
    "    \"\"\"Invoke the specified tool.\"\"\"\n",
    "    tool_name_to_tool = {tool.name: tool for tool in tools}\n",
    "    name = tool_call_request[\"name\"]\n",
    "    requested_tool = tool_name_to_tool[name]\n",
    "    return requested_tool.invoke(tool_call_request[\"arguments\"])\n",
    "\n",
    "# Example invocation\n",
    "result = invoke_tool({\"name\": \"multiply\", \"arguments\": {\"x\": 3, \"y\": 5}})\n",
    "print(result)  # Output: 15.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Everything\n",
    "Finally, chain everything together and invoke the chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.0\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | model | JsonOutputParser() | invoke_tool\n",
    "response = chain.invoke({\"input\": \"what's thirteen times 4\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
