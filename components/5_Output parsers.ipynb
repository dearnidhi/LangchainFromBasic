{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Parsers\n",
    "Output parsers are responsible for taking the output of an LLM and transforming it to a more suitable format. This is very useful when you are using LLMs to generate any form of structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is an Output Parser?\n",
    "An output parser takes the raw text output from an LLM and processes it into structured data formats, such as lists, JSON, dates, or even custom data structures. This is valuable in NLP workflows where parsed data can be processed, analyzed, or integrated into applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Use Output Parsers?\n",
    "Consistency: Ensures model outputs are always in the same format.\n",
    "\n",
    "Usability: Structured data is easier to manipulate and integrate.\n",
    "\n",
    "Error Handling: Allows retry or error-correction mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing JSON Output \n",
    "We can use the JsonOutputParser class to parse this output into a Python dictionary:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John', 'age': 30, ' occupation': 'Developer'}\n"
     ]
    }
   ],
   "source": [
    "import groq\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Assume you have an LLM output in JSON format\n",
    "llm_output = '{\"name\": \"John\", \"age\": 30, \" occupation\": \"Developer\"}'\n",
    "\n",
    "# Create an instance of the JsonOutputParser\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# Parse the LLM output\n",
    "parsed_output = parser.parse(llm_output)\n",
    "\n",
    "print(parsed_output)  # Output: {'name': 'John', 'age': 30, 'occupation': 'Developer'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse XML output\n",
    "\n",
    "To parse XML output, you can use the XMLOutputParser. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: defusedxml\n",
      "Successfully installed defusedxml-0.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install defusedxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some model output data here\n"
     ]
    }
   ],
   "source": [
    "from defusedxml import ElementTree\n",
    "\n",
    "# Well-formed XML string for testing\n",
    "xml_data = \"<response><data>Some model output data here</data></response>\"\n",
    "root = ElementTree.fromstring(xml_data)\n",
    "print(root.find('data').text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to parse YAML output\n",
    "\n",
    "To parse YAML output, you can use the JsonOutputParser with the yaml library. Here's an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* if you’re dealing with YAML outputs, you can load it directly without trying to convert it to JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John', 'age': 30, 'occupation': 'Developer'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Your YAML output string\n",
    "llm_output = \"\"\"name: John\n",
    "age: 30\n",
    "occupation: Developer\"\"\"\n",
    "\n",
    "# Load YAML to a dictionary\n",
    "parsed_output = yaml.safe_load(llm_output)\n",
    "\n",
    "print(parsed_output)  # Output: {'name': 'John', 'age': 30, 'occupation': 'Developer'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can convert your input to a proper JSON string before passing it to the JsonOutputParser. Here's how you can do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John', 'age': 30, 'occupation': 'Developer'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Your string output that needs to be converted to JSON format\n",
    "llm_output = \"\"\"name: John\n",
    "age: 30\n",
    "occupation: Developer\"\"\"\n",
    "\n",
    "# Manually convert the output to valid JSON\n",
    "# You can use yaml.safe_load if you expect to deal with YAML regularly.\n",
    "import yaml\n",
    "data_dict = yaml.safe_load(llm_output)\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "json_output = json.dumps(data_dict)\n",
    "\n",
    "# Initialize the parser\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# Parse the JSON string\n",
    "parsed_output = parser.parse(json_output)\n",
    "\n",
    "print(parsed_output)  # Output: {'name': 'John', 'age': 30, 'occupation': 'Developer'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PydanticOutputParser\n",
    "The PydanticOutputParser uses Pydantic models to enforce a specific structure for the language model’s output. Pydantic is a Python library for data validation and parsing, and it lets you define expected fields, types, and validation rules for your data. By using PydanticOutputParser, you can ensure that responses from the language model meet your required schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action='search' action_input='leo di caprio girlfriend'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define the expected structure of the response\n",
    "class Action(BaseModel):\n",
    "    action: str = Field(description=\"action to take\")\n",
    "    action_input: str = Field(description=\"input to the action\")\n",
    "\n",
    "# Initialize the PydanticOutputParser with the Action model\n",
    "parser = PydanticOutputParser(pydantic_object=Action)\n",
    "\n",
    "# Example response to parse\n",
    "response = '{\"action\": \"search\", \"action_input\": \"leo di caprio girlfriend\"}'\n",
    "parsed_output = parser.parse(response)\n",
    "\n",
    "print(parsed_output)\n",
    "# Output: Action(action='search', action_input='leo di caprio girlfriend')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  RetryOutputParser\n",
    "The RetryOutputParser is used when the language model’s output does not match the expected structure, causing an error in parsing (e.g., if the output is missing fields). It’s essentially a layer that attempts to get a corrected response from the model by retrying with an additional prompt. The RetryOutputParser leverages a secondary language model call, providing the original model’s response along with a reminder of the required output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action='search' action_input='leo di caprio girlfriend'\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import RetryOutputParser\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define the Action model to parse the response into structured fields\n",
    "class Action(BaseModel):\n",
    "    action: str = Field(description=\"action to take\")\n",
    "    action_input: str = Field(description=\"input to the action\")\n",
    "\n",
    "# Initialize the PydanticOutputParser with the Action model\n",
    "parser = PydanticOutputParser(pydantic_object=Action)\n",
    "\n",
    "# Define a prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Based on the user question, provide an Action and Action Input for what step should be taken.\\n{format_instructions}\\nQuestion: {query}\\nResponse:\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Format the prompt with a user query\n",
    "prompt_value = prompt_template.format_prompt(query=\"who is leo di caprio's girlfriend?\")\n",
    "\n",
    "# Initialize the RetryOutputParser with a language model for retry attempts\n",
    "retry_parser = RetryOutputParser.from_llm(parser=parser, llm=OpenAI(temperature=0))\n",
    "\n",
    "# Use parse_with_prompt instead of parse\n",
    "try:\n",
    "    # \"bad_response\" simulates an incomplete or incorrect response that caused the initial parse to fail\n",
    "    bad_response = '{\"action\": \"search\"}'\n",
    "    parsed_output = retry_parser.parse_with_prompt(bad_response, prompt_value)\n",
    "    print(parsed_output)\n",
    "except Exception as e:\n",
    "    print(\"Parse failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
