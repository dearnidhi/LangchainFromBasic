{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to add default invocation args to a Runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for Using .bind() with Hugging Face and Runnable:\n",
    "Define the model and pipeline: In this case, we’ll use a Hugging Face pipeline (e.g., for text generation or question answering).\n",
    "\n",
    "Use .bind() to set default arguments: Similar to how you'd bind OpenAI-specific parameters like stop sequences, you can bind runtime arguments for Hugging Face models.\n",
    "Combine with Runnable components: Use RunnablePassthrough and RunnableParallel as needed.v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Using Hugging Face for a Text Generation Task with Default Invocation Args\n",
    "Here’s how you can implement the approach with Hugging Face for generating jokes and poems with default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': 'tell me a joke about bear meat, and I\\'m gonna put out an angry tweet about that! — Andrew Gelman (@garantamcj) February 15, 2017\\n\\n@garantamcj \"There\\'s some other shit going', 'poem': 'write a 2-line poem about bear cubs in winter, and his latest effort is in the form of a poem that chronicles his love affair with Siberian bear cubs from his time as a child. The title is a pun on the term'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from transformers import pipeline\n",
    "\n",
    "# Define Hugging Face pipeline for text generation (e.g., using GPT-2 for jokes and poems)\n",
    "joke_pipeline = pipeline(\"text-generation\", model=\"gpt2\")  # Use GPT-2 for joke generation\n",
    "poem_pipeline = pipeline(\"text-generation\", model=\"gpt2\")  # Use GPT-2 for poem generation\n",
    "\n",
    "# Create chains for joke and poem generation\n",
    "joke_chain = lambda input_data: joke_pipeline(f\"tell me a joke about {input_data['topic']}\")[0]['generated_text']\n",
    "poem_chain = lambda input_data: poem_pipeline(f\"write a 2-line poem about {input_data['topic']}\")[0]['generated_text']\n",
    "\n",
    "# Create a parallel map of tasks (generating joke and poem simultaneously)\n",
    "map_chain = RunnableParallel(joke=joke_chain, poem=poem_chain)\n",
    "\n",
    "# Bind a default invocation argument for the topic (to avoid needing to pass it every time)\n",
    "map_chain = map_chain.bind(topic=\"bear\")\n",
    "\n",
    "# Directly invoke the parallel chain and pass 'topic' in the input\n",
    "response = map_chain.invoke({\"topic\": \"bear\"})  # Ensure 'topic' is included in the input\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
