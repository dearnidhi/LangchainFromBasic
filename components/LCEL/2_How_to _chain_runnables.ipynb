{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # How to chain runnables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Chaining of Runnables\n",
    "\n",
    "To chain runnables in LangChain, follow these steps:\n",
    "\n",
    "* Define Prompt Template: Start with a prompt that formats the input.\n",
    "* Model Setup: Feed the formatted prompt to a chat model, such as ChatGroq.\n",
    "* Output Parsing: Pass the model output to an output parser to get the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Code to Chain Runnables\n",
    "Below is the code example using | (pipe operator):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the bear go to the doctor?\n",
      "\n",
      "Because it had a grizzly cough!\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatGroq(model=\"llama3-8b-8192\")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "\n",
    "# Chain the prompt, model, and output parser using the pipe operator\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# Invoke the chain with a topic as input\n",
    "result = chain.invzyoke({\"topic\": \"bears\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using .pipe() Method\n",
    "Alternatively, you can build the same chain using .pipe(), which works identically to the pipe operator |:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the bear go to the doctor?\n",
      "\n",
      "Because it had a grizzly cough!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "# Create the chain using the pipe method\n",
    "chain_pipe = RunnableSequence(prompt, model, StrOutputParser())\n",
    "\n",
    "# Run the chain\n",
    "result_pipe = chain_pipe.invoke({\"topic\": \"bears\"})\n",
    "print(result_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a Custom Runnable for Evaluation\n",
    "If you want to add a custom step, such as evaluating the joke for humor, you can use a lambda function or custom RunnableLambda in the chain. Here’s how you’d do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think it's a paws-itively hilarious joke!\n",
      "\n",
      "The play on words between \"grizzly\" (meaning fierce or intense) and \"grizzly\" (the type of bear) is clever and unexpected, which makes it a funny joke. The punchline is unexpected and adds a layer of cleverness to the joke, making it more enjoyable.\n",
      "\n",
      "The joke also relies on a simple and relatable setup (a bear going to the doctor), which makes the unexpected twist even more surprising and amusing.\n",
      "\n",
      "Overall, I think the joke is a good example of a well-crafted pun, and it's likely to elicit a chuckle or a smile from most people!\n"
     ]
    }
   ],
   "source": [
    "# Define another prompt to analyze if the joke is funny\n",
    "analysis_prompt = ChatPromptTemplate.from_template(\"is this a funny joke? {joke}\")\n",
    "\n",
    "# Compose a new chain that includes joke evaluation\n",
    "composed_chain = (\n",
    "    chain\n",
    "    | (lambda joke_text: {\"joke\": joke_text}z)\n",
    "    | analysis_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Invoke the composed chain\n",
    "result_analysis = composed_chain.invoke({\"topic\": \"bears\"})\n",
    "print(result_analysis)z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running in Parallel\n",
    "If you want multiple chains to run in parallel and combine their results, use RunnableParallel. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classic joke! Yes, this is a funny joke! It's a play on words, using the literal meaning of \"space\" (as in, outer space) and the idiomatic phrase \"need some space\" (meaning to need time and distance from someone or something). The punchline is unexpected and clever, making it amusing. Well done, joke creator!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Run the joke generation and analysis in parallel\n",
    "parallel_chain = RunnableParallel({\"joke\": chain}).pipe(analysis_prompt, model, StrOutputParser())\n",
    "\n",
    "# Invoke with input topic\n",
    "result_parallel = parallel_chain.invoke({\"topic\": \"space\"})\n",
    "print(result_parallel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
