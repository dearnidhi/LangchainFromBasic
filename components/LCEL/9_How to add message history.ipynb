{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to add message history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph allows you to manage message history (and other stateful data) in multi-turn chatbot applications by:\n",
    "\n",
    "* Storing conversation state (e.g., user messages, responses).\n",
    "* Supporting memory across multiple interactions or threads (e.g., conversations with different users).\n",
    "* Using persistence to store the state in memory, SQLite, Postgres, or Redis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How It Works\n",
    "  1 . Initialize the Chat Model: Use your preferred Large Language Model (e.g., OpenAI, Anthropic). This model will handle chat interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a Graph to Handle State: A StateGraph manages the message history and interaction flow. The graph has:\n",
    "\n",
    "* A state schema: Defines the structure of the stored data (e.g., messages).\n",
    "* Nodes: Represent steps in the workflow (e.g., calling the model).\n",
    "* Edges: Connect the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.53-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langgraph) (0.3.21)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.32 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.36-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.1.136)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.10.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph)\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.27.2)\n",
      "Requirement already satisfied: httpx-sse>=0.4.0 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.4.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10.9)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.2.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\desktop\\10-20-2024\\venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.2.2)\n",
      "Downloading langgraph-0.2.53-py3-none-any.whl (125 kB)\n",
      "Downloading langgraph_checkpoint-2.0.6-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_sdk-0.1.36-py3-none-any.whl (29 kB)\n",
      "Downloading msgpack-1.1.0-cp310-cp310-win_amd64.whl (74 kB)\n",
      "Installing collected packages: msgpack, langgraph-sdk, langgraph-checkpoint, langgraph\n",
      "Successfully installed langgraph-0.2.53 langgraph-checkpoint-2.0.6 langgraph-sdk-0.1.36 msgpack-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a graph with a schema for storing messages\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# Define a function to call the model and update the message history\n",
    "def call_model(state: MessagesState):\n",
    "    response = llm.invoke(state[\"messages\"])  # Get response from LLM\n",
    "    return {\"messages\": response}  # Add response to message history\n",
    "\n",
    "# Add the function as a node in the graph\n",
    "workflow.add_edge(START, \"model\")  # Connect START to the model node\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory to store the state between runs\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)  # Compile the graph with memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run the Application: Invoke the graph by:\n",
    "\n",
    "* Passing messages to the model.\n",
    "* Using a thread_id to manage separate conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Bob! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# First query: Introduce yourself\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}  # Conversation ID\n",
    "query = \"Hi! I'm Bob.\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "\n",
    "# Print the AI response\n",
    "output[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Handle Multiple Turns: Pass new queries while keeping the same thread_id to retain memory:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob. How can I help you today, Bob?\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "\n",
    "# Print the AI response\n",
    "output[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Separate Threads: Use a new thread_id to start a fresh conversation with no memory:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, but I don't know your name. If you'd like to share it, feel free to do so!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
    "query = \"What's my name?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "\n",
    "output[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Access and Update State:\n",
    "\n",
    "  * View State:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='8a7f7a4b-28d8-4b61-b56a-c5ebe448625d'), AIMessage(content=\"I'm sorry, but I don't know your name. If you'd like to share it, feel free to do so!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 11, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-7202d73c-743a-401f-ae30-de677160b0fa-0', usage_metadata={'input_tokens': 11, 'output_tokens': 23, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "state = app.get_state(config).values\n",
    "print(state[\"messages\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Update State: Add messages manually:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': 'abc234',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1eface2d-feaa-6569-8002-bcb95b659f33'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "app.update_state(config, {\"messages\": [HumanMessage(\"Test\")]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Use This Approach?\n",
    "Persistence: Store and manage conversation history effortlessly.\n",
    "\n",
    "Multi-user Support: Separate threads for different users.\n",
    "\n",
    "Flexibility: Use in-memory storage or external databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Workflow\n",
    "Initialize the model.\n",
    "\n",
    "Create a graph with StateGraph.\n",
    "\n",
    "Add memory to the graph.\n",
    "\n",
    "Run queries with a thread_id to manage conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
